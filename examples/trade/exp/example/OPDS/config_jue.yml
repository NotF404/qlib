seed: 42
task: train
policy_path: null
log_dir: /mnt/data/quant/qlib/examples/log/example/OPDS_2/
buffer_size: 80000
io_conf:
  test_sampler: 
    name: Sampler
    config:
      train_start_date: "20180918"
      train_end_date: "20210630"
      valid_start_date: "20210701"
      valid_end_date: "20220704"
      test_start_date: "20210701"
      test_end_date: "20220704"
      instruments: "all_2018"
      day_cache_dir: '/mnt/data/quant/qlib/data/day_data_cache_dir'
      min_data_dir: "/mnt/stockdata/eastmoney_min_data/"
      n_days: 5
      is_train: true
      is_realtime: false
  train_sampler: 
    name: Sampler
    config:
      train_start_date: "20180918"
      train_end_date: "20210630"
      valid_start_date: "20210701"
      valid_end_date: "20220704"
      test_start_date: "20210701"
      test_end_date: "20220704"
      instruments: "all_2018"
      day_cache_dir: '/mnt/data/quant/qlib/data/day_data_cache_dir'
      min_data_dir: "/mnt/stockdata/eastmoney_min_data/"
      n_days: 5
      is_train: False
      is_realtime: false
  test_logger: DFLogger
resources:
  num_cpus: 12
  num_gpus: 1
  device: cuda
env_conf:
  name: JueStockEnv
  is_buy: false
  obs:
    name: JueObs
    config: {
      feature_size: 6,
      perfect_info: false
    }
  action:
    name: Static_Action
    config:
      action_num: 3
      action_map: [0.1, 0.0, 0.2]
      is_buy: false
  reward:
    VP_Penalty_small_vec:
      penalty: 100
      coefficient: 1
policy_conf:
  name: PPO
  config:
    discount_factor: 1.
    max_grad_norm: 100.
    reward_normalization: False
    eps_clip: 0.3
    value_clip: True
    vf_coef: 1.
    gae_lambda: 1.
    vf_clip_para: 0.3
network_conf:
  name: Teacher
  extractor:
    name: NSTransformer
    config:
      pred_len: 1
      seq_len: 964
      label_len: 121
      enc_in: 2
      dec_in: 4
      c_out: 128
      dropout: 0.05
      d_model: 512
      freq: 't'
  actor:
    name: Teacher_Actor
    config: 
      out_shape: 3
      in_shape: 128
  critic:
    name: Teacher_Critic
    config:
      out_shape: 1
      in_shape: 128

optim:
  lr: 5e-5
  batch_size: 16
  max_epoch: 10
  step_per_epoch: 2
  collect_per_step: 40000
  repeat_per_collect: 2
  early_stopping: 10
  weight_decay: 0.0001